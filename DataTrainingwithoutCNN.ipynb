{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "#import effTools as eff\n",
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import json\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_available = [\"Training\",\"Testing\"]\n",
    "dataset = datasets_available\n",
    "img_width, img_height = 150, 150\n",
    "image_size = (150, 150)\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "pool_size = 2\n",
    "classes_num = 2 #change\n",
    "batch_size = 32\n",
    "lr = 0.0004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2022-05-27 12:33\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 630, 630, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 630, 630, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 315, 315, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 315, 315, 64)      8256      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 315, 315, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 315, 157, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 315, 157, 128)     16512     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 315, 157, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 315, 78, 64)       0         \n",
      "=================================================================\n",
      "Total params: 25,664\n",
      "Trainable params: 25,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] successfully loaded base model and model...\n",
      "[INFO] encoding labels...\n",
      "[INFO] completed label - no\n",
      "[INFO] completed label - yes\n",
      "[STATUS] training labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[STATUS] training labels shape: (253,)\n",
      "ok\n",
      "[STATUS] start time - 2022-05-27 12:34\n",
      "[INFO] successfully loaded base model and model...\n",
      "[INFO] encoding labels...\n",
      "[INFO] completed label - no\n",
      "[INFO] completed label - yes\n",
      "[STATUS] training labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[STATUS] training labels shape: (253,)\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "for ds in range(0, len(dataset)):\n",
    "    model_name    = \"preprocesss\"\n",
    "    weights       = \"imagenet\"\n",
    "    include_top   = 0 \n",
    "    train_path    = \"preprocess/\" + dataset[ds]\n",
    "    features_path = \"output/\" +dataset[ds]+ \"/features.h5\" \n",
    "    labels_path   = \"output/\" +dataset[ds]+ \"/labels.h5\"\n",
    "\n",
    "    #test_size     = test_set[ds]\n",
    "    \n",
    "    # check if the output directory exists, if not, create it.\n",
    "    #eff.check_if_directory_exists(\"output\")\n",
    "    \n",
    "    # check if the output directory exists, if not, create it.\n",
    "    #eff.check_if_directory_exists(\"output/\" + dataset[ds])\n",
    "    \n",
    "    # start time\n",
    "    print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "    start = time.time()\n",
    "    \n",
    "    if ds==0:\n",
    "        img_width, img_height = 630,630\n",
    "        image_size = (630, 630)\n",
    "        nb_train_samples = 2000\n",
    "        nb_validation_samples = 800\n",
    "        nb_filters1 = 32\n",
    "        nb_filters2 = 64\n",
    "        nb_filters3 = 128\n",
    "        conv1_size = 3\n",
    "        conv2_size = 2\n",
    "        conv3_size = 2\n",
    "        pool_size = 2\n",
    "        classes_num = 2 #change\n",
    "        batch_size = 32\n",
    "        lr = 0.0004\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(nb_filters1, (conv1_size, conv1_size), padding=\"same\", input_shape=(img_width, img_height, 3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "        model.add(Conv2D(nb_filters2, (conv2_size, conv2_size), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_first'))\n",
    "        \n",
    "        model.add(Conv2D(nb_filters3, (conv3_size, conv3_size), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_first'))\n",
    "        \n",
    "        model.summary()\n",
    "   \n",
    "        \n",
    "    # check if the output directory exists, if not, create it.\n",
    "    #eff.check_if_directory_exists(\"output/\" + dataset[ds] + \"/\" + model_name)\n",
    "    \n",
    "    print (\"[INFO] successfully loaded base model and model...\")\n",
    "    \n",
    "    # path to training dataset\n",
    "    train_labels = os.listdir(train_path)\n",
    "    \n",
    "    # encode the labels\n",
    "    print (\"[INFO] encoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    le.fit([tl for tl in train_labels])\n",
    "    \n",
    "    # variables to hold features and labels\n",
    "    features = []\n",
    "    labels   = []\n",
    " \n",
    "    count = 1\n",
    "    for i, label in enumerate(train_labels):   \n",
    "      cur_path = train_path+ \"/\" + label\n",
    "       # check how many files are, together with their extensions\n",
    "      #print(cur_path)\n",
    "      list_files = os.listdir(cur_path)  \n",
    "      count = 1\n",
    "      #for image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "      for image_path in range(0, len(list_files)):\n",
    "        img = cv2.imread(cur_path + \"/\" + list_files[image_path]) \n",
    "        img = cv2.resize(img, (630,630)) \n",
    "        cv2.imwrite('1.jpg', img)\n",
    "        #print (\"[INFO] Processing - \" + str(count) + \" named \" + list_files[image_path])\n",
    "        img = image.load_img('1.jpg')\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        \n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        feature = model.predict(x)\n",
    "        flat = feature.flatten()\n",
    "        features.append(flat)\n",
    "        #print(flat)\n",
    "        \n",
    "        labels.append(label)\n",
    "        #print (\"[INFO] processed for image - \" + list_files[image_path])\n",
    "        count += 1\n",
    "      print (\"[INFO] completed label - \" + label)\n",
    "    \n",
    "    imgs = cv2.imread('1.jpg')    \n",
    "    img_gray = cv2.cvtColor(imgs, cv2.COLOR_BGR2GRAY)\n",
    "    r, threshold = cv2.threshold(img_gray, 125, 255, cv2.THRESH_BINARY)\n",
    "    edged = cv2.Canny(img_gray, 100,200)\n",
    "    contours, hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  \n",
    "    cv2.drawContours(img_gray, contours, -1, (0, 255, 0), 3)\n",
    "    # encode the labels using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    le_labels = le.fit_transform(labels)\n",
    "    \n",
    "    # get the shape of training labels\n",
    "    print (\"[STATUS] training labels: {}\".format(le_labels))\n",
    "    print (\"[STATUS] training labels shape: {}\".format(le_labels.shape))\n",
    "    \n",
    "    # save features and labels\n",
    "    try:\n",
    "        h5f_data = h5py.File(features_path, 'w')\n",
    "    except:\n",
    "        a=1;\n",
    "        \n",
    "    h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
    "    \n",
    "    h5f_label = h5py.File(labels_path, 'w')\n",
    "    h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
    "    \n",
    "    h5f_data.close()\n",
    "    h5f_label.close()\n",
    "    print('ok')\n",
    "    if ds==0:\n",
    "        model.save('output/model1.h5')\n",
    "        model_json = model.to_json()\n",
    "        with open('output/model1.json', \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        model.save_weights('output/weights1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "!pip install matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_datatrain  = h5py.File('output/Training/features.h5', 'r')\n",
    "h5f_labeltrain = h5py.File('output/Training/labels.h5', 'r')\n",
    "h5f_datatest  = h5py.File('output/Testing/features.h5', 'r')\n",
    "h5f_labeltest = h5py.File('output/Testing/labels.h5', 'r')\n",
    "\n",
    "features_stringtrain = h5f_datatrain['dataset_1']\n",
    "labels_stringtrain   = h5f_labeltrain['dataset_1']\n",
    "features_stringtest = h5f_datatest['dataset_1']\n",
    "labels_stringtest   = h5f_labeltest['dataset_1']\n",
    "\n",
    "featurestrain = np.array(features_stringtrain)\n",
    "labelstrain   = np.array(labels_stringtrain)\n",
    "\n",
    "featurestest = np.array(features_stringtest)\n",
    "labelstest   = np.array(labels_stringtest)\n",
    "\n",
    "h5f_datatrain.close()\n",
    "h5f_labeltrain.close()\n",
    "h5f_datatest.close()\n",
    "h5f_labeltest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train data: (253, 1572480)\n",
      "[INFO] train label: (253,)\n",
      "[INFO] test data: (253, 1572480)\n",
      "[INFO] test label: (253,)\n"
     ]
    }
   ],
   "source": [
    "print (\"[INFO] train data: {}\".format(featurestrain.shape))\n",
    "print (\"[INFO] train label: {}\".format(labelstrain.shape))\n",
    "print (\"[INFO] test data: {}\".format(featurestest.shape))\n",
    "print (\"[INFO] test label: {}\".format(labelstest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "#from deeplearning import graph, output_list\n",
    "import cv2\n",
    "import time\n",
    "import joblib\n",
    "#from sklearn.externals import joblib \n",
    "#import pymysql as mdb\n",
    "print('k')\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "json_file = open('output/model1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"output/weights1.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2022-05-27 12:04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85        98\n",
      "           1       0.93      0.86      0.89       155\n",
      "\n",
      "    accuracy                           0.87       253\n",
      "   macro avg       0.87      0.88      0.87       253\n",
      "weighted avg       0.88      0.87      0.87       253\n",
      "\n",
      "train complete\n",
      "[STATUS] End Time - 2022-05-27 12:05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "filename = 'knn_model.sav'\n",
    "joblib.dump(neigh, filename)\n",
    "neigh.fit(featurestrain, labelstrain)\n",
    "preds = neigh.predict(featurestest)\n",
    "print(classification_report(labelstest, preds))\n",
    "joblib.dump(neigh, filename)\n",
    "\n",
    "\n",
    "print('train complete')\n",
    "print (\"[STATUS] End Time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2022-05-27 09:33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78        98\n",
      "           1       0.84      0.92      0.88       155\n",
      "\n",
      "    accuracy                           0.84       253\n",
      "   macro avg       0.84      0.82      0.83       253\n",
      "weighted avg       0.84      0.84      0.84       253\n",
      "\n",
      "train complete\n",
      "[STATUS] End time - 2022-05-27 09:45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "neigh = SVC()\n",
    "filename = 'svm_model.sav'\n",
    "joblib.dump(neigh, filename)\n",
    "neigh.fit(featurestrain, labelstrain)\n",
    "preds = neigh.predict(featurestrain)\n",
    "print(classification_report(labelstrain, preds))\n",
    "joblib.dump(neigh, filename)\n",
    "\n",
    "\n",
    "print('train complete')\n",
    "print (\"[STATUS] End time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\jayesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "Y18.JPG\n",
      "1\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-31d2bbea4834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mmydb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     mydb = mdb.connect(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "\n",
    "##myfile = 'oo.jpg'\n",
    "##imag=cv2.imread(myfile)\n",
    "##imag=cv2.resize(imag, (630,630))\n",
    "a=['Benign','Malignant']          \n",
    "!pip install pymysql\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "##from deeplearning import graph, model, output_list\n",
    "import cv2\n",
    "import requests\n",
    "import pymysql as mdb\n",
    "\n",
    "import time\n",
    "def upd(disease, ids):\n",
    "    \n",
    "    mydb = mdb.connect(\n",
    "      host=\"127.0.0.1\",\n",
    "      user=\"root\",\n",
    "      passwd=\"\",\n",
    "      database=\"370project\"\n",
    "    )\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "   \n",
    "\n",
    "    sql = \"UPDATE disease SET disease = %s WHERE ids = %s\"\n",
    "    val = (disease, ids)\n",
    "\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()\n",
    "    mydb.close()\n",
    "while True:\n",
    "    time.sleep(2)\n",
    "    print('ok')\n",
    "    mydb = mdb.connect(\n",
    "          host=\"127.0.0.1\",\n",
    "          user=\"root\",\n",
    "          passwd=\"\",\n",
    "          database=\"370project\"\n",
    "        )\n",
    "\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"SELECT ids,pic,disease FROM disease\"\n",
    "\n",
    "\n",
    "    mycursor.execute(sql)\n",
    "    fine=0\n",
    "    myresult = mycursor.fetchall()\n",
    "    mydb.close()\n",
    "    #print (myresult)\n",
    "    for x in myresult:\n",
    "        \n",
    "      ids= str(x[0])\n",
    "      pic=str(x[1])\n",
    "      fl=str(x[2])\n",
    "      #print (ids,pic,fl)\n",
    "      if fl=='1': \n",
    "        print('ok')\n",
    "        print(pic)\n",
    "        pic='D:/xampp/htdocs/imgsent/process/images/'+pic\n",
    "        myfile = pic    \n",
    "        img = cv2.imread(myfile) \n",
    "        img = cv2.resize(img, (630,630)) \n",
    "        cv2.imwrite('1.jpg', img)\n",
    "        #print (\"[INFO] Processing - \" + str(count) + \" named \" + list_files[image_path])\n",
    "        img = image.load_img('1.jpg')\n",
    "        imgs = cv2.imread('1.jpg')    \n",
    "        img_gray = cv2.cvtColor(imgs, cv2.COLOR_BGR2GRAY)\n",
    "        r, threshold = cv2.threshold(img_gray, 125, 255, cv2.THRESH_BINARY)\n",
    "        edged = cv2.Canny(img_gray, 100,200)\n",
    "        contours, hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  \n",
    "        cv2.drawContours(imgs, contours, -1, (0, 255, 0), 3) \n",
    "        \n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = preprocess_input(img)        \n",
    "        prediction = loaded_model.predict(img)\n",
    "        prediction_flatten = prediction.flatten()\n",
    "        \n",
    "        knn_from_joblib = joblib.load('knn_model.sav')\n",
    "        prediction_flatten=prediction_flatten.reshape(1,-1)\n",
    "        max_val_index=knn_from_joblib.predict(prediction_flatten) \n",
    "\n",
    "        max_val_index=int(max_val_index)\n",
    "        print (max_val_index)   \n",
    "        \n",
    "        pred='Tumor Is '\n",
    "        disease=(pred+a[max_val_index])\n",
    "        upd(disease, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
